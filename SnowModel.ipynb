{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to read in variables from the nc files created when grads files are converted using cdo \n",
    "#Command is:   cdo -f nc import_binary file.ctl ofile.nc \n",
    "#Had to adapt Glen's .ctl files to put distances in meters, even though they're called lat and lon the variables are actually \n",
    "# From Glen re the 09_16 files No. The 1 Aug 2008 through 31 July 2009 run assimilates the Mar-Apr 2009 data. My notation has been that I call simulation year 08-09 = 09, 15-16 = 16.\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset\n",
    "from scipy.io import netcdf\n",
    "from scipy.spatial import distance\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import savefig\n",
    "import datetime\n",
    "import pandas\n",
    "import glob\n",
    "import scipy\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WARREN COMPARISON\n",
    "#Get monthly averages using cdo monmean snod_ease_grid.nc monthly_mean_test.nc (worked even over multiple years)\n",
    "\n",
    "#Get information about the grids using cdo's griddes; here I've got the grid size from the snow model and adapted the Warren grid file to keep lat/lon and just change the resolution\n",
    "#! cdo griddes /Users/samanthabuzzard/Liston_May_v2/sm_oib_2009-2016/erai/sm_09/snod_ease_grid.nc > myGridDef\n",
    "#! cdo griddes /Volumes/n4_cpdata/scb/MONTHLY_GRIDS/WARREN/12_WarrenSnowDens.nc > myGridDef\n",
    "for modelrun in ['09_16']:\n",
    "    for variable in ['snod', 'sden']:\n",
    "        for forcing in ['erai', 'merra']:\n",
    "            if modelrun=='36yrs':\n",
    "                for year in range (1980,2017,1):\n",
    "                    if year==1980:\n",
    "                        for month in range (8,13,1):\n",
    "                            compare=Compare_With_Warren(forcing,year,month,variable,modelrun)\n",
    "                    if year==2016:\n",
    "                        for month in range (1,8,1):\n",
    "                            compare=Compare_With_Warren(forcing,year,month,variable,modelrun)\n",
    "                    else:\n",
    "                        for month in range (1,13,1):\n",
    "                            compare=Compare_With_Warren(forcing,year,month,variable,modelrun)\n",
    "            if modelrun=='09_16':\n",
    "                    for year in range (2009,2015,1):\n",
    "                        for month in range (1,13,1):\n",
    "                            compare, x2, y2=Compare_With_Warren(forcing,year,month,variable,modelrun)\n",
    "                    for month in range (8,13,1):\n",
    "                        compare=Compare_With_Warren(forcing,'2008',month,variable,modelrun)\n",
    "                    for month in range (1,8,1):\n",
    "                        compare=Compare_With_Warren(forcing,'2015',month,variable,modelrun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Buoys comparison\n",
    "\n",
    "CRREL_buoys=['2013D', '2013A', '2013B', '2013C', '2013E', '2013F', '2013G', '2013H', '2013I', '2014B', '2014C', '2014D', '2014E', '2014I' ]\n",
    "for buoy in range(0, len(CRREL_buoys), 1):\n",
    "   # Compare_with_buoy(CRREL_buoys[buoy], 'erai', '09_16', 'CRREL')\n",
    "   # Compare_with_buoy(CRREL_buoys[buoy], 'merra', '09_16', 'CRREL')\n",
    "    Compare_with_buoy(CRREL_buoys[buoy], 'erai', '36yrs', 'CRREL')\n",
    "    Compare_with_buoy(CRREL_buoys[buoy], 'merra', '36yrs', 'CRREL')\n",
    "\n",
    "# #S1 S6 S7 s8 S9 s10 s11 s12 s14 s15 s16 s17 s21 s24 s25 s29 s31 s33 s37 s40 s46 data corrupt (negative values)\n",
    "# #S17 S18 S19 S24 'S39','S41','S42','S44','S45','S43','S47','S48','S51','S52','S53' contan no matching points\n",
    "# #S32 values are way too high test divide by 1000\n",
    "# AWI_buoys=['S3','S4','S13','S18','S19','S20','S22','S23','S26','S27','S28','S30','S35','S36']\n",
    "# #AWI_buoys=['S32']\n",
    "# for buoy in range(0, len(AWI_buoys), 1):\n",
    "#     Compare_with_buoy(AWI_buoys[buoy], 'erai', '09_16', 'AWI')\n",
    "#     Compare_with_buoy(AWI_buoys[buoy], 'merra', '09_16', 'AWI')\n",
    "#     #Compare_with_buoy(AWI_buoys[buoy], 'erai', '36yrs', 'AWI')\n",
    "#     #Compare_with_buoy(AWI_buoys[buoy], 'merra', '36yrs', 'AWI')\n",
    "run_buoy_stats_annual()\n",
    "run_buoys_stats_buoys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OIB \n",
    "#Files stored as OIB_all_yyyy_mm_dd.txt have have lon lat snod(m)\n",
    "#Nearest neighbour comparison didn't work as too many points with similar values so went with binning\n",
    "#Only keep bins with >100 points as in Petty 2018 eularian snow model evaluation\n",
    "\n",
    "for modelrun in ['09_16']:\n",
    "    for year in range(2009,2016,1):\n",
    "        for forcing in ['erai', 'merra']:\n",
    "            Compare_OIB(year,forcing,modelrun)\n",
    "\n",
    "run_OIB_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot Glen's OIB tracks\n",
    "filepath='/Users/samanthabuzzard/Liston_May_v2/snod_over_OIB_lines/data/'\n",
    "plot_oib_tracks(filepath+'snod_w-den_assim_','merra2' )\n",
    "plot_oib_tracks(filepath+'snod_w-den_assim_', 'erai')\n",
    "plot_oib_tracks(filepath+'snod_mod_oib_', 'erai')\n",
    "plot_oib_tracks(filepath+'snod_mod_oib_', 'merra2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shalina comparison\n",
    "#Shalina says usesful for M-A-M\n",
    "\n",
    "modelruns=['09_16']\n",
    "forcings=['erai', 'merra']\n",
    "\n",
    "for modelrun in modelruns:\n",
    "    for forcing in forcings:\n",
    "        if modelrun=='09_16':\n",
    "            for year in range(2009,2017,1):\n",
    "                for month in range(3,6,1):\n",
    "                    Compare_Shalina(forcing,year,month,modelrun,'linear')\n",
    "        if modelrun=='36yrs':\n",
    "            for year in range(1980,2017,1):\n",
    "                for month in range(3,6,1):\n",
    "                    Compare_Shalina(forcing,year,month,modelrun,'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############FUNCTIONS IN HERE################\n",
    "\n",
    "\n",
    "######Read in SnowModel nc files \n",
    "\n",
    "def Readin_SnowModel_0916(forcing,year,variable):\n",
    "    \"\"\"2009 to 2016 yearly files. Variables are 'sden' or 'snod'\"\"\"\n",
    "    yearname='%02d' %(int(str(year)[(len(str(year))-2):]))\n",
    "    filepath='/Users/samanthabuzzard/Liston_May_v2/sm_oib_2009-2015/'+forcing+'/'+'sm_'+str(yearname)+'/'\n",
    "    f = Dataset(filepath+variable+'_ease_grid.nc', 'r')\n",
    "    lon= f.variables['lon'][:]\n",
    "    lat=f.variables['lat'][:]\n",
    "    snow=f.variables[variable][:]\n",
    "    x1, y1=np.meshgrid(lon, lat)\n",
    "    return snow,x1,y1\n",
    "\n",
    "def Readin_SnowModel_36(forcing,variable):\n",
    "    \"\"\"Have 1st Aug 1980 for 36 years, includes leap years total of 13149 days. Variables are 'sden' or 'snod'\"\"\"  \n",
    "    filepath='/Users/samanthabuzzard/Liston_May_v2/sm_36yrs/'+forcing+'/'\n",
    "    f = Dataset(filepath+variable+'_ease_grid.nc', 'r')\n",
    "    lon= f.variables['lon'][:]\n",
    "    lat=f.variables['lat'][:]\n",
    "    snow=f.variables[variable][:]\n",
    "    x1, y1=np.meshgrid(lon, lat)\n",
    "    return snow,x1,y1\n",
    "\n",
    "#Get daily data \n",
    "def Get_daily_data_0916(snow,year,month,day):\n",
    "    #Model runs for 365 days regardless of leap year\n",
    "    #Run is named after the year OIB data is in i.e. sm_09 starts in Aug 2008\n",
    "    if month in range(1,8,1):\n",
    "        d0 = datetime.date(year-1, 8, 1)\n",
    "    else:\n",
    "        d0 = datetime.date(year, 8, 1)\n",
    "    d1 = datetime.date(year,month,day)\n",
    "    delta = d1 - d0\n",
    "    date=delta.days\n",
    "    snow_daily=snow[date,:,:]         \n",
    "    return snow_daily\n",
    "    \n",
    "def Get_daily_data_36(snow,year,month,day):\n",
    "    d0 = datetime.date(1980, 8, 1)\n",
    "    d1 = datetime.date(year, month, day)\n",
    "    delta = d1 - d0\n",
    "    date=delta.days\n",
    "    snow_daily=snow[date,:,:]\n",
    "    return snow_daily   \n",
    "\n",
    "########Warren Comparison\n",
    "\n",
    "def Compare_With_Warren(forcing,year,month,variable,modelrun):\n",
    "    #SnowModel data\n",
    "    yearname='%02d' %(int(str(year)[(len(str(year))-2):]))\n",
    "    if modelrun=='09_16':\n",
    "        #First month (i.e. position 0) will be August\n",
    "        if month in range (1,8,1):\n",
    "            month_number=month+4\n",
    "        else:\n",
    "            month_number=month-8\n",
    "            yearname='%02d' %(int(str(year)[(len(str(year))-2):])+1)\n",
    "        snowmodel_filepath='/Users/samanthabuzzard/Liston_May_v2/sm_oib_2009-2015/'+forcing+'/'+'sm_'+str(yearname)+'/'    \n",
    "    if modelrun=='36yrs':\n",
    "        snowmodel_filepath='/Users/samanthabuzzard/Liston_May_v2/sm_36yrs/'+forcing+'/'\n",
    "        month_number=(year-1980)*12+month-8\n",
    "    f1 = Dataset(snowmodel_filepath+'monthly_mean_'+variable+'.nc', 'r')\n",
    "    snow_model=f1.variables[variable][month_number,:]\n",
    "    #Warren data\n",
    "    monthname='%02d' %(month)\n",
    "    if variable=='sden':\n",
    "        variablename='Dens'\n",
    "    if variable=='snod':\n",
    "        variablename='Depth'\n",
    "    warren_filepath='/Volumes/n4_cpdata/scb/MONTHLY_GRIDS/WARREN/'+str(monthname)+'_WarrenSnow'+variablename+'.nc'\n",
    "    ! ncatted -a long_name,y,m,c,\"latitude\"  $warren_filepath  #fixes generic variable z unroecognised error: remapbil needs specific variable names\n",
    "    ! ncatted -a long_name,x,m,c,\"longitude\"  $warren_filepath\n",
    "    ! cdo remapbil,myGridDef $warren_filepath temp.nc  \n",
    "    f2 = Dataset('temp.nc', 'r')\n",
    "    snow_warren=f2.variables['z'][:]\n",
    "    \n",
    "    if modelrun=='36yrs':\n",
    "    #deal with differences in Glen's nc files\n",
    "        snow_model=snow_model[0]\n",
    "        f2 = Dataset('/Users/samanthabuzzard/Liston_May_v2/sm_oib_2009-2015/erai/sm_09/monthly_mean_snod.nc', 'r')\n",
    "        lon= f2.variables['lon'][:]\n",
    "        lat= f2.variables['lat'][:]\n",
    "        x1, y1=np.meshgrid(lon, lat)\n",
    "    else: \n",
    "        lon= f1.variables['lon'][:]\n",
    "        lat=f1.variables['lat'][:]\n",
    "        x1, y1=np.meshgrid(lon, lat)\n",
    "    comp=snow_model-snow_warren\n",
    "    \n",
    "    Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "    inProj = Proj(init='epsg:3408')#Replace6931  \n",
    "    outProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "    xx, yy = transform(inProj,outProj,x1,y1)\n",
    "    m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "    x2,y2=m(xx,yy)\n",
    "    m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "    m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "    m.drawcoastlines(linewidth=0.5)\n",
    "    month_numbers=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    if variable == 'sden':\n",
    "        m.pcolormesh(x2, y2, comp, cmap='RdBu_r', vmin=-200, vmax=200)\n",
    "        cb = plt.colorbar()\n",
    "        cb.set_label('Snow density difference ($kgm^{-3}$)')\n",
    "        plt.title('Snow model monthly average - Warren for '+month_numbers[month-1]+'/'+str(year))\n",
    "    else:\n",
    "        m.pcolormesh(x2, y2, comp, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "        cb = plt.colorbar()\n",
    "        cb.set_label('Snow depth difference (m)')\n",
    "        plt.title('Snow model monthly average - Warren for '+month_numbers[month-1]+'/'+str(year))\n",
    "    m.fillcontinents(color='grey')\n",
    "    fig_savepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/WARREN/COMPARISONS_'+modelrun+'/'\n",
    "    plt.savefig(fig_savepath+'Warrencomparison_'+modelrun+'_'+forcing+str(year)+'_'+str(monthname)+'_'+variable+'.jpeg', dpi=1000)\n",
    "    plt.show() \n",
    "    return comp, x2, y2\n",
    "\n",
    "########Compare Buoys\n",
    "\n",
    "def Compare_with_buoy(buoy_name, forcing, modelrun, buoys):\n",
    "    buoy_lats=[]\n",
    "    buoy_lons=[]\n",
    "    buoy_snow=[]\n",
    "    buoy_year=[]\n",
    "    buoy_month=[]\n",
    "    buoy_day=[]\n",
    "    modelled_snow=[]\n",
    "    buoy_snow_keep=[]\n",
    "    buoy_year_keep=[]\n",
    "    distances=[]\n",
    "    model_x=[]\n",
    "    model_y=[]\n",
    "    month_numbers=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    if buoys=='CRREL':\n",
    "            Buoy_files=sorted(glob.glob('/Volumes/n4_cpdata/scb/SNOW_DATA/BUOYS/CRREL/SORTED/av_'+buoy_name+'*.txt'))\n",
    "            figure_path='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/BUOYS/CRREL/'\n",
    "    if buoys=='AWI':\n",
    "            #AWI files have buoys that cover more than one year- the 20* ensures that e.g. S1 and S10 don't get mixed up\n",
    "            Buoy_files=sorted(glob.glob('/Volumes/n4_cpdata/scb/SNOW_DATA/BUOYS/AWI/SORTED/av_'+buoy_name+'20*.txt'))\n",
    "            figure_path='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/BUOYS/AWI/'\n",
    "\n",
    "    if Buoy_files!=[]:\n",
    "        for item in Buoy_files:\n",
    "            data=(np.loadtxt(item))\n",
    "            buoy_lats.append(data[0])\n",
    "            buoy_lons.append(data[1])\n",
    "            buoy_snow.append(data[2])\n",
    "            buoy_year.append(int(item[len(item)-12:len(item)-8]))\n",
    "            buoy_month.append(item[len(item)-8:len(item)-6])\n",
    "            buoy_day.append(item[len(item)-6:len(item)-4])\n",
    "\n",
    "        if modelrun=='36yrs':\n",
    "            snow, x1, y1=Readin_SnowModel_36(forcing,'snod') #Takes too long to open to do this every time (reopen 09_16 every time as year may change)\n",
    "\n",
    "        for point in range(0,len(buoy_snow),1):\n",
    "            if modelrun=='09_16':\n",
    "                if (int(buoy_year[point])<2008) or (int(buoy_year[point])>2016):\n",
    "                    continue\n",
    "                if int(buoy_month[point])>7:\n",
    "                    snow, x1, y1=Readin_SnowModel_0916(forcing,buoy_year[point],'snod')\n",
    "                else:\n",
    "                    snow, x1, y1=Readin_SnowModel_0916(forcing,int(buoy_year[point])-1,'snod')\n",
    "                snow_model=Get_daily_data_0916(snow,int(buoy_year[point]),int(buoy_month[point]),int(buoy_day[point]))\n",
    "            if modelrun=='36yrs':\n",
    "                if (int(buoy_year[point])>2016):\n",
    "                    continue\n",
    "                snow_model=Get_daily_data_36(snow,int(buoy_year[point]),int(buoy_month[point]),int(buoy_day[point]))[0]\n",
    "            if (buoy_lons[point]>180 or buoy_lons[point]<-180 or buoy_lats[point]>90 or buoy_lats[point]<-90):\n",
    "                print('data invalid for '+str(buoy_name)+' '+str(buoy_day[point])+'/'+str(buoy_month[point])+'/'+str(buoy_year[point]))\n",
    "                continue\n",
    "            XX,YY = np.meshgrid(np.arange(snow_model.shape[1]),np.arange(snow_model.shape[0]))\n",
    "            table = np.vstack((XX.ravel(),YY.ravel())).T\n",
    "            x2, y2=np.meshgrid(buoy_lons[point], buoy_lats[point])\n",
    "            outProj = Proj(init='epsg:3408')\n",
    "            inProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "            #Buoys are transformed to EASE grid \n",
    "            xx, yy = transform(inProj,outProj,x2,y2)\n",
    "            model_grid = list( zip(np.ravel(x1), np.ravel(y1)) ) \n",
    "            target_pts = [xx[0][0], yy[0][0]] \n",
    "            if (str(target_pts[0])=='nan' or str(target_pts[1])=='nan'):\n",
    "                continue\n",
    "            distance, index = scipy.spatial.cKDTree(model_grid).query(target_pts)  #cKDTree is faster than KDTree for simple queries like this\n",
    "            # the nearest model location (in lat and lon)\n",
    "            #model_loc_coord = [coord for i, coord in enumerate(model_grid) if i==index]\n",
    "            nearest_x=table[index][0]\n",
    "            nearest_y=table[index][1]\n",
    "            modelled_snow.append(snow_model[nearest_x, nearest_y])\n",
    "            buoy_snow_keep.append(buoy_snow[point])\n",
    "            buoy_year_keep.append(buoy_year[point])\n",
    "            distances.append(distance)\n",
    "            if distance>25000:\n",
    "                print('WARNING- comparison point more than 25km away for day '+str(buoy_name)+' '+str(buoy_day[point])+'/'+str(buoy_month[point])+'/'+str(buoy_year[point])+'distance='+str(distance))\n",
    "\n",
    "            model_x.append(x1[0][nearest_x])\n",
    "            model_y.append(y1[nearest_y][0])\n",
    "          \n",
    "        np.savetxt(figure_path+buoy_name+str(forcing)+'_'+str(modelrun)+'.txt',np.c_[buoy_snow_keep[:],modelled_snow,buoy_year_keep[:]])\n",
    "            \n",
    "        plt.plot([i * 1 for i in buoy_snow[:]], label='IMBdepth', color='black') \n",
    "        plt.plot(modelled_snow,'--', label='Snow Model depth', color='red')# color=colours[count] if plotting several for one year\n",
    "        plt.xlabel('Day (starting '+str(buoy_day[0])+' '+month_numbers[int(buoy_month[0])]+' '+str(buoy_year[0])+')')\n",
    "        plt.ylabel('snow depth (m)')\n",
    "        plt.title('IMB vs Snow Model '+forcing+': buoy '+buoy_name)\n",
    "        plt.legend(loc='lower right', bbox_to_anchor=(1.39, 0.785))\n",
    "        plt.savefig(figure_path+buoy_name+'_'+forcing+'_'+modelrun+\".png\",dpi=100,bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "        m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "        m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "        m.drawcoastlines(linewidth=0.5)\n",
    "        x4,y4=m(buoy_lons,buoy_lats)\n",
    "        m.scatter(x4,y4, s=1, marker='o',color='r')\n",
    "        Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "        inProj = Proj(init='epsg:3408')#Replace6931  \n",
    "        outProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "        x3, y3=np.meshgrid(model_x, model_y)\n",
    "        xx3, yy3 = transform(inProj,outProj,x3,y3)\n",
    "        xxx3,yyy3=m(xx3,yy3)\n",
    "        m.scatter(np.ravel(xxx3),np.ravel(yyy3), s=1, marker='o',color='b')\n",
    "        m.fillcontinents(color='grey')\n",
    "        plt.savefig(figure_path+buoy_name+'_'+forcing+'_'+modelrun+\"_map.png\",dpi=100,bbox_inches='tight')\n",
    "        plt.show() \n",
    "        plt.clf()\n",
    "        \n",
    "        \n",
    "#Buoy stats (annual)\n",
    "def run_buoy_stats_annual():\n",
    "    years=[]\n",
    "    forcings=[]\n",
    "    modelruns=[]\n",
    "    mean_bias=[]\n",
    "    RMSE=[]\n",
    "    mean_bias.append('mean_bias')\n",
    "    RMSE.append('RMSE')\n",
    "    years.append('year')\n",
    "    forcings.append('forcing')\n",
    "    modelruns.append('model_run')\n",
    "\n",
    "    for buoys in ['CRREL', 'AWI']:\n",
    "        filepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/BUOYS/'+buoys+'/'\n",
    "        for year in range(2009,2016,1):\n",
    "            model_snow=[]\n",
    "            buoy_snow=[]\n",
    "            for forcing in ['erai','merra']:\n",
    "                for modelrun in ['09_16','36yrs']:\n",
    "                    #Probably not the most efficient way but will catch buoys that span multiple years\n",
    "                    files=sorted(glob.glob(filepath+'*'+str(forcing)+'_'+str(modelrun)+'.txt'))\n",
    "                    for file in files:\n",
    "                        data=np.loadtxt(file)\n",
    "                        for point in range(0,len(data),1): #check len data is this and not 3\n",
    "                            if int(data[point,2])==year:\n",
    "                                model_snow.append(data[point,1])\n",
    "                                buoy_snow.append(data[point,0])\n",
    "                    if model_snow != []:\n",
    "\n",
    "                        mean_bias.append(np.nanmean(np.array(model_snow)-np.array(buoy_snow)))\n",
    "                        RMSE.append(np.nanmean((np.array(model_snow)-np.array(buoy_snow))**2.0)**(1/2.0))\n",
    "                        years.append(year)\n",
    "                        forcings.append(forcing)\n",
    "                        modelruns.append(modelrun)\n",
    "\n",
    "                        model_snow_hist=np.array(model_snow)\n",
    "                        buoy_snow_hist=np.array(buoy_snow)\n",
    "\n",
    "                        bins = np.linspace(0, 1, 21)\n",
    "                        plt.hist(model_snow_hist[~np.isnan(model_snow_hist)], bins, alpha=0.5, label='modelled snow '+forcing)\n",
    "                        plt.hist(buoy_snow_hist[~np.isnan(buoy_snow_hist)], bins, alpha=0.5, label='buoy snow')\n",
    "                        plt.legend(loc='upper right')\n",
    "                        plt.title('Modelled and buoys snow depths for '+str(year))\n",
    "                        plt.xlabel('snow depth (m)')\n",
    "                        plt.savefig(filepath+'Hist_'+str(year)+'_'+forcing+modelrun+'.png')\n",
    "                        plt.show()\n",
    "\n",
    "        np.savetxt(filepath+'__stats.txt',np.c_[years, forcings, modelruns, mean_bias, RMSE],fmt='%s')\n",
    "        \n",
    "        \n",
    "#Buoy histograms by buoy\n",
    "\n",
    "def run_buoy_stats_buoys():\n",
    "\n",
    "    CRREL_buoys=['2013D', '2013A', '2013B', '2013C', '2013E', '2013F', '2013G', '2013H', '2013I', '2014B', '2014C', '2014D', '2014E', '2014I' ]\n",
    "    AWI_buoys=['S3','S4','S13','S18','S19','S20','S22','S23','S26','S27','S28','S30','S35','S36']\n",
    "\n",
    "    for buoys in ['CRREL', 'AWI']:\n",
    "        filepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/BUOYS/'+buoys+'/'\n",
    "        if buoys=='CRREL':\n",
    "            for buoy in CRREL_buoys:\n",
    "                model_snow_erai=[]\n",
    "                model_snow_merra=[]\n",
    "                buoy_snow=[]\n",
    "                data_erai=np.loadtxt(filepath+buoy+'_erai_09_16.txt')\n",
    "                data_merra=np.loadtxt(filepath+buoy+'_merra_09_16.txt')\n",
    "                for point in range(0,len(data),1): #check len data is this and not 3\n",
    "                    model_snow_erai.append(data_erai[point,0])\n",
    "                    model_snow_merra.append(data_merra[point,0])\n",
    "                    buoy_snow.append(data1[point,1])\n",
    "                if model_snow != []:\n",
    "                    model_snow_hist_erai=np.array(model_snow_erai)\n",
    "                    model_snow_hist_merra=np.array(model_snow_merra)\n",
    "                    buoy_snow_hist=np.array(buoy_snow)\n",
    "                    bins = np.linspace(0, 1, 21)\n",
    "                    plt.hist(model_snow_hist[~np.isnan(model_snow_hist_erai)], bins, alpha=0.5, label='ERAI modelled snow')\n",
    "                    plt.hist(model_snow_hist[~np.isnan(model_snow_hist_merra)], bins, alpha=0.5, label='MERRA2 modelled snow')\n",
    "                    plt.hist(buoy_snow_hist[~np.isnan(buoy_snow_hist)], bins, alpha=0.5, label='buoy snow')\n",
    "                    plt.legend(loc='upper right')\n",
    "                    plt.title('Modelled and buoys snow depths for '+str(buoy))\n",
    "                    plt.xlabel('snow depth (m)')\n",
    "                    plt.savefig(filepath+'Hist_'+str(buoy)+'_'+modelrun+'.png')\n",
    "                    plt.show()\n",
    "        if buoys=='AWI':\n",
    "            for buoy in AWI_buoys:\n",
    "                model_snow_erai=[]\n",
    "                model_snow_merra=[]\n",
    "                buoy_snow=[]\n",
    "                data_erai=np.loadtxt(filepath+buoy+'_erai_09_16.txt')\n",
    "                data_merra=np.loadtxt(filepath+buoy+'_merra_09_16.txt')\n",
    "                for point in range(0,len(data),1): #check len data is this and not 3\n",
    "                    model_snow_erai.append(data_erai[point,0])\n",
    "                    model_snow_merra.append(data_merra[point,0])\n",
    "                    buoy_snow.append(data1[point,1])\n",
    "                if model_snow != []:\n",
    "                    model_snow_hist_erai=np.array(model_snow_erai)\n",
    "                    model_snow_hist_merra=np.array(model_snow_merra)\n",
    "                    buoy_snow_hist=np.array(buoy_snow)\n",
    "                    bins = np.linspace(0, 1, 21)\n",
    "                    plt.hist(model_snow_hist[~np.isnan(model_snow_hist_erai)], bins, alpha=0.5, label='ERAI modelled snow')\n",
    "                    plt.hist(model_snow_hist[~np.isnan(model_snow_hist_merra)], bins, alpha=0.5, label='MERRA2 modelled snow')\n",
    "                    plt.hist(buoy_snow_hist[~np.isnan(buoy_snow_hist)], bins, alpha=0.5, label='buoy snow')\n",
    "                    plt.legend(loc='upper right')\n",
    "                    plt.title('Modelled and buoys snow depths for '+str(buoy))\n",
    "                    plt.xlabel('snow depth (m)')\n",
    "                    plt.savefig(filepath+'Hist_'+str(buoy)+'_'+modelrun+'.png')\n",
    "                    plt.show()\n",
    "    \n",
    "########Compare OIB\n",
    "\n",
    "def Compare_OIB(year,forcing,modelrun):\n",
    "    OIB_lats=[]\n",
    "    OIB_lons=[]\n",
    "    OIB_snow=[]\n",
    "    OIB_month=[]\n",
    "    OIB_day=[]\n",
    "    modelled_snow=[]\n",
    "    model_x=[]\n",
    "    model_y=[]\n",
    "    OIB_snow_keep=[]\n",
    "    model_snow_keep=[]\n",
    "    diff_keep=[]\n",
    "    lats_keep=[]\n",
    "    lons_keep=[]\n",
    "\n",
    "    if modelrun=='09_16':\n",
    "        snow,x1,y1=Readin_SnowModel_0916(forcing,year,'snod')\n",
    "    if modelrun=='36yrs':\n",
    "        snow,x1,y1=Readin_SnowModel_36(forcing,'snod')\n",
    "\n",
    "\n",
    "    OIB_files=sorted(glob.glob('/Volumes/n4_cpdata/scb/SNOW_DATA/LISTON_v2/VALIDATION/OIB/DAILY_FILES/OIB_all_'+str(year)+'*.txt'))\n",
    "    for item in OIB_files:\n",
    "        data=(np.loadtxt(item))\n",
    "        if data!=[]:\n",
    "            for point in range(0,len(data),1):\n",
    "                OIB_lons.append(data[point][0])\n",
    "                OIB_lats.append(data[point][1])\n",
    "                OIB_snow.append(data[point][2])\n",
    "                OIB_month.append(item[len(item)-9:len(item)-7])\n",
    "                OIB_day.append(item[len(item)-6:len(item)-4])\n",
    "\n",
    "            Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "            outProj = Proj(init='epsg:3408')#Replace6931  \n",
    "            inProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "            xx, yy = transform(inProj,outProj,OIB_lons,OIB_lats)\n",
    "\n",
    "            for month in range(3,5,1):\n",
    "                for day in range(1,32,1):\n",
    "                    daily_snow=[]\n",
    "                    daily_lons=[]\n",
    "                    daily_lats=[]\n",
    "                    for point in range(0,len(data),1):\n",
    "                        if (int(OIB_month[point])==month) and (int(OIB_day[point])==day):\n",
    "                            daily_snow.append(OIB_snow[point])\n",
    "                            daily_lons.append(xx[point])\n",
    "                            daily_lats.append(yy[point])\n",
    "                    if daily_snow!=[]:\n",
    "                        if modelrun=='09_16':\n",
    "                            daily_model_snow=Get_daily_data_0916(snow,year,month,day)\n",
    "                        if modelrun=='36yrs':\n",
    "                            daily_model_snow=Get_daily_data_36(snow,year,month,day)\n",
    "                        x_bins=np.arange(-4525000, 4500001, 25000)#have to make end point slightly over final value wanted because... python\n",
    "                        y_bins=np.arange(-4525000, 4500001, 25000)#bins also have to start 1 before grid to create 361x361\n",
    "                        #Works like histogram- y values come first\n",
    "                        H2D = stats.binned_statistic_2d(daily_lats, daily_lons, daily_snow, statistic='mean',bins=[x_bins,y_bins])\n",
    "                        count = stats.binned_statistic_2d(daily_lats, daily_lons, daily_snow, statistic='count',bins=[x_bins,y_bins])\n",
    "\n",
    "                        for a in range(0,(len(H2D[1])-1),1):\n",
    "                            for b in range(0,(len(H2D[2])-1),1):\n",
    "                                if count[0][a,b]>100:\n",
    "                                    OIB_snow_keep.append(H2D[0][a,b])\n",
    "                                    model_snow_keep.append(daily_model_snow[a,b])\n",
    "                                    diff_keep.append(daily_model_snow[a,b]-H2D[0][a,b])\n",
    "                                    lats_keep.append(H2D[1][a])\n",
    "                                    lons_keep.append(H2D[2][b])\n",
    "\n",
    "    savepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/OIB/BINNED/'\n",
    "\n",
    "    np.savetxt(savepath+str(year)+str(forcing)+str(modelrun)+'.txt',np.c_[model_snow_keep,OIB_snow_keep])\n",
    "\n",
    "\n",
    "    m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "\n",
    "\n",
    "    #Plot OIB track over April average for given year\n",
    "    x_bins=np.arange(-180, 180.0000001, (360-1/12)/360)\n",
    "    y_bins=np.arange((30-1/6), 90.000001, 60/360)\n",
    "    H2D_all = stats.binned_statistic_2d(OIB_lats, OIB_lons, OIB_snow, statistic='mean',bins=[y_bins,x_bins])\n",
    "    x3,y3=np.meshgrid(H2D_all[2],H2D_all[1])\n",
    "    x2,y2=m(x3,y3)\n",
    "    m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "    m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "    m.drawcoastlines(linewidth=0.5)\n",
    "\n",
    "    if modelrun=='09_16':\n",
    "            snowmodel_filepath='/Users/samanthabuzzard/Liston_May_v2/sm_oib_2009-2015/'+forcing+'/'+'sm_'+str(year)[2:4]+'/'    \n",
    "            #First month (i.e. position 0) will be August\n",
    "            if month in range (1,8,1):\n",
    "                month_number=month+4\n",
    "            else:\n",
    "                month_number=month-8\n",
    "    if modelrun=='36yrs':\n",
    "            snowmodel_filepath='/Users/samanthabuzzard/Liston_May_v2/sm_36yrs/'+forcing+'/'\n",
    "            month_number=(year-1980)*12+month-8\n",
    "    f1 = Dataset(snowmodel_filepath+'monthly_mean_'+'snod'+'.nc', 'r')\n",
    "    snow_model=f1.variables['snod'][month_number,:]\n",
    "    Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "    inProj = Proj(init='epsg:3408')#Replace6931  \n",
    "    outProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "    xx, yy = transform(inProj,outProj,x1,y1)\n",
    "    m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "    x4,y4=m(xx,yy)\n",
    "    m.pcolormesh(x4,y4,snow_model,cmap='coolwarm', vmin=-0.5, vmax=0.5)\n",
    "    cb = plt.colorbar()\n",
    "    m.pcolormesh(x2, y2,(H2D_all[0]), cmap='Blues', vmin=-0.5, vmax=0.5)\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('Snow depth (m)')\n",
    "    plt.title('Snowmodel (Apr average) and OIB tracks for '+str(year))\n",
    "    plt.savefig(savepath+str(year)+str(forcing)+str(modelrun)+'map.png')\n",
    "    plt.show()\n",
    "\n",
    "    #Scatterplot of results\n",
    "    plt.clf()\n",
    "    plt.scatter(OIB_snow_keep,model_snow_keep)\n",
    "    plt.title('Snowmodel vs OIB snow depths for '+str(year))\n",
    "    plt.xlabel('OIB snow depth (m)')\n",
    "    plt.ylabel('Snow model snow depth (m)')\n",
    "    plt.savefig(savepath+str(year)+str(forcing)+str(modelrun)+'scatter.png')\n",
    "    plt.show()\n",
    "    \n",
    "    #Plot difference between results\n",
    "    plt.clf()\n",
    "    m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "    Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "    inProj = Proj(init='epsg:3408')#Replace6931  \n",
    "    outProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "    xx, yy = transform(inProj,outProj,lons_keep, lats_keep)\n",
    "    x2,y2=m(xx,yy)\n",
    "    m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "    m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "    m.drawcoastlines(linewidth=0.5)\n",
    "    m.scatter(np.array(x2),np.array(y2),c=diff_keep,cmap='viridis',s=5,vmin=-0.5, vmax=0.5)\n",
    "    plt.title('Difference between snow model and OIB for '+str(year)+' '+forcing)\n",
    "    m.fillcontinents(color='grey')\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('Snow depth difference (m)')\n",
    "    plt.savefig(savepath+str(year)+str(forcing)+str(modelrun)+'differencemap.png')\n",
    "    plt.show()\n",
    "    \n",
    "#OIB stats\n",
    "\n",
    "def run_OIB_stats():\n",
    "\n",
    "    years=[]\n",
    "    forcings=[]\n",
    "    modelruns=[]\n",
    "    mean_bias=[]\n",
    "    RMSE=[]\n",
    "    mean_bias.append('mean_bias')\n",
    "    RMSE.append('RMSE')\n",
    "    years.append('year')\n",
    "    forcings.append('forcing')\n",
    "    modelruns.append('model_run')\n",
    "\n",
    "    filepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/OIB/BINNED/'\n",
    "    for year in range(2009,2016,1):\n",
    "        for forcing in ['erai','merra']:\n",
    "            for modelrun in ['09_16']:\n",
    "                file=filepath+str(year)+forcing+modelrun+'.txt'\n",
    "                data=np.loadtxt(file)\n",
    "                model_snow=data[:,0]\n",
    "                OIB_snow=data[:,1]\n",
    "                mean_bias.append(np.nanmean(model_snow-OIB_snow))\n",
    "                RMSE.append(np.nanmean((model_snow-OIB_snow)**2.0))**(1/2.0)\n",
    "                years.append(year)\n",
    "                forcings.append(forcing)\n",
    "                modelruns.append(modelrun)\n",
    "    np.savetxt(filepath+'_stats.txt',np.c_[years, forcings, modelruns, mean_bias, RMSE],fmt='%s')\n",
    "    \n",
    "    \n",
    "#OIB tracks using Glen's files\n",
    "\n",
    "def plot_oib_tracks(file, forcing): \n",
    "    f1 = Dataset(file+forcing+'.nc', 'r')\n",
    "    model_snow=f1.variables['mod']\n",
    "    oib_snow=f1.variables['oib']\n",
    "    lon=f1.variables['lon']\n",
    "    lat=f1.variables['lat']\n",
    "    for year in range(2009, 2016, 1):\n",
    "        year_number=year-2009\n",
    "        difference=model_snow[year_number][0]-oib_snow[year_number][0]\n",
    "        plt.clf()\n",
    "        m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "        Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "        inProj = Proj(init='epsg:3408')#Replace6931  \n",
    "        outProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "        x, y=np.meshgrid(lon,lat)\n",
    "        x1, y1 = transform(inProj,outProj,x, y)\n",
    "        x2,y2=m(x1,y1)\n",
    "        m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "        m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "        m.drawcoastlines(linewidth=0.5)\n",
    "        m.scatter(np.array(x2),np.array(y2),c=difference,cmap='viridis',s=8,vmin=-0.5, vmax=0.5)\n",
    "        plt.title('Difference between snow model and OIB for '+str(year)+' '+forcing)\n",
    "        m.fillcontinents(color='grey')\n",
    "        cb = plt.colorbar()\n",
    "        cb.set_label('Snow depth difference (m)')\n",
    "        plt.savefig('/Volumes/n4_cpdata-1/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/OIB/LISTON/'+file[62:(len(file)-3)]+'_differencemap.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#############Shalina\n",
    "\n",
    "def Read_in_Shalina(grid_x,grid_y,interp_method):\n",
    "\n",
    "    df = pandas.read_excel('/Volumes/n4_cpdata/scb/SNOW_DATA/SHALINA/grid_data.xlsx')\n",
    "    #print the column names\n",
    "    print (df.columns)\n",
    "    #get the values for a given column\n",
    "    X = df['X'].values #in polar stereographic\n",
    "    Y = df['Y'].values\n",
    "    snow = df['snow depth in cm'].values #in cm\n",
    "    inProj=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=20 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\");\n",
    "    #close to polar stereographic but different latitude of origin/ central meridian so adapted above \n",
    "    outProj = Proj(init='epsg:4326') #lat lon\n",
    "    xx, yy = transform(inProj,outProj, X, Y)\n",
    "\n",
    "    ##Test grids are in same domain\n",
    "    #plt.scatter(x2,y2)\n",
    "    #plt.hold('True')\n",
    "    #plt.scatter(x1,y1)\n",
    "    #plt.show()\n",
    "    \n",
    "    #Code to define a grid- not used here but useful to keep\n",
    "    #grid_x, grid_y=np.mgrid[(-180+(1/12)):180:361j, 30:90:361j]#j means the final value is included\n",
    "\n",
    "\n",
    "    m = Basemap(projection='npstere',boundinglat=60,lon_0=0, resolution='l')\n",
    "    x1,y1=m(xx,yy)\n",
    "    snow2=griddata((x1,y1), snow, (grid_x,grid_y), method=interp_method)\n",
    "    \n",
    "    ##PLOT \n",
    "    #m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "    #m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "    #m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "    #m.drawcoastlines(linewidth=0.5)\n",
    "    #m.pcolormesh(x2, y2, snow2_linear, cmap='RdBu_r')\n",
    "    #m.fillcontinents(color='grey')\n",
    "    ##plt.axis([lon.min(), lon.max(), lat.min(), lat.max()]) #messes things up when there are nans!\n",
    "    #cb = plt.colorbar()\n",
    "    #cb.set_label('Snow depth difference (m)')\n",
    "    #plt.show() \n",
    "    return snow2\n",
    "\n",
    "def Compare_Shalina(forcing,year,month,modelrun,interp_method):\n",
    "    #Compare with monthly snow model data\n",
    "    yearname='%02d' %(int(str(year)[(len(str(year))-2):]))\n",
    "    if modelrun=='09_16':\n",
    "        snowmodel_filepath='/Users/samanthabuzzard/Liston_May_v2/sm_oib_2009-2015/'+forcing+'/'+'sm_'+str(yearname)+'/'\n",
    "        f1 = Dataset(snowmodel_filepath+'monthly_mean_snod.nc', 'r')\n",
    "        #First month (i.e. position 0) will be August\n",
    "        if month in range (1,8,1):\n",
    "            month_number=month+4\n",
    "        else:\n",
    "            month_number=month-8\n",
    "    if modelrun=='36yrs':\n",
    "        snowmodel_filepath='/Users/samanthabuzzard/Liston_May_v2/sm_36yrs/'+forcing+'/'\n",
    "        f1 = Dataset(snowmodel_filepath+'monthly_mean_snod.nc', 'r')\n",
    "        month_number=(year-1980)*12+month-8\n",
    "    snow_model=f1.variables['snod'][month_number,:]\n",
    "    lon= f1.variables['lon'][:]\n",
    "    lat=f1.variables['lat'][:]\n",
    "    x1, y1=np.meshgrid(lon, lat)\n",
    "    Replace6931=pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"); #close to polar stereographic but different latitude of origin/ central meridian so adapted above\n",
    "    inProj = Proj(init='epsg:3408')#Replace6931  \n",
    "    outProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "    xx, yy = transform(inProj,outProj,x1,y1)\n",
    "    m = Basemap(projection='npstere',boundinglat=60,lon_0=0,resolution='l')\n",
    "    x2,y2=m(xx,yy) \n",
    "    #Shalina data\n",
    "    sh_snow=Read_in_Shalina(x2,y2,interp_method)\n",
    "    m.drawparallels(np.arange(60,90,10), linewidth = 0.25, linestyle='solid', zorder=8)\n",
    "    m.drawmeridians(np.arange(0.,360.,30.), linewidth = 0.25, zorder=8)\n",
    "    m.drawcoastlines(linewidth=0.5)\n",
    "    month_numbers=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    comp=snow_model-sh_snow/100\n",
    "    m.pcolormesh(x2, y2, comp, cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('Snow depth difference (m)')\n",
    "    plt.title('Snow model monthly average ('+forcing+')- Shalina for '+month_numbers[month-1]+' '+str(year))\n",
    "    m.fillcontinents(color='grey')\n",
    "    fig_savepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/SHALINA/'\n",
    "    monthname='%02d' %(month)\n",
    "    plt.savefig(fig_savepath+'Shalinacomparison_09_16_'+forcing+str(year)+'_'+str(monthname)+'.jpeg', dpi=1000)\n",
    "    plt.show() \n",
    "    return comp, xx, yy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This should work but need older data to compare to- run when have Glen's files\n",
    "\n",
    "forcing='erai'\n",
    "modelrun='09_16'\n",
    "savepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/SUMUP/'\n",
    "mean_bias=[]\n",
    "RMSE=[]\n",
    "modelled_snow=[]\n",
    "sumup_snow=[]\n",
    "lats_keep=[]\n",
    "lons_keep=[]\n",
    "for point in range ((len(df)-10), len(df),1):\n",
    "    year=str(df.iloc[point][0])[0:4]\n",
    "    if int(year) >= 2009 and int(year) <= 2015:\n",
    "        snow,x1,y1=Readin_SnowModel_0916(forcing,year,'snod')\n",
    "        month=str(df.iloc[point][0])[4:6]\n",
    "        day=str(df.iloc[point][0])[6:8]\n",
    "        lat=df.iloc[point][1]\n",
    "        lon=df.iloc[point][2]\n",
    "        snod=df.iloc[point][4]\n",
    "        snod_error=df.iloc[point][5]\n",
    "        snow_model=Get_daily_data_0916(snow,int(year),int(month),int(day))\n",
    "        \n",
    "        XX,YY = np.meshgrid(np.arange(snow_model.shape[1]),np.arange(snow_model.shape[0]))\n",
    "        table = np.vstack((XX.ravel(),YY.ravel())).T\n",
    "        x2, y2=np.meshgrid(lat, lon)\n",
    "        outProj = Proj(init='epsg:3408')\n",
    "        inProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "        #Sumup points are transformed to EASE grid \n",
    "        xx, yy = transform(inProj,outProj,x2,y2)\n",
    "        model_grid = list( zip(np.ravel(x1), np.ravel(y1)) ) \n",
    "        target_pts = [xx[0][0], yy[0][0]] \n",
    "        if (str(target_pts[0])=='nan' or str(target_pts[1])=='nan'):\n",
    "            continue\n",
    "        distance, index = scipy.spatial.cKDTree(model_grid).query(target_pts)  #cKDTree is faster than KDTree for simple queries like this\n",
    "        print(distance)\n",
    "        # the nearest model location (in lat and lon)\n",
    "        #model_loc_coord = [coord for i, coord in enumerate(model_grid) if i==index]\n",
    "        nearest_x=table[index][0]\n",
    "        nearest_y=table[index][1]\n",
    "        modelled_snow.append(snow_model[nearest_x, nearest_y])\n",
    "        sumup_snow.append(snod)\n",
    "        lats_keep.append(lat)\n",
    "        lons_keep.append(lon)\n",
    "\n",
    "mean_bias.append(np.nanmean(np.array(modelled_snow)-np.array(sumup_snow)))\n",
    "RMSE.append(np.nanmean((np.array(modelled_snow)-np.array(sumup_snow))**2.0)**(1/2.0))\n",
    "\n",
    "\n",
    "#Scatterplot of results\n",
    "plt.clf()\n",
    "plt.scatter(sumup_snow,modelled_snow)\n",
    "plt.title('Snowmodel ('+forcing+') vs SUMUP snow depths')\n",
    "plt.xlabel('SUMUP snow depth (m)')\n",
    "plt.ylabel('Snow model snow depth (m)')\n",
    "plt.savefig(savepath+'sumup_comparison_'+str(forcing)+str(modelrun)+'scatter.png')\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(filepath+'_stats.txt',np.c_[years, forcings, modelruns, mean_bias, RMSE],fmt='%s')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#N-ICE data and code to make it in n4_cpdata/scb/SNOW_DATA/NPOLAR/ReadN_ICE.ipynb\n",
    "for forcing in ['erai', 'merra']:\n",
    "\n",
    "    modelrun='09_16'\n",
    "    year=2015\n",
    "\n",
    "    savepath='/Volumes/n4_cpdata/scb/SNOW_DATA/SNOWMODEL_EASE/VALIDATION/NICE/'\n",
    "    mean_bias=[]\n",
    "    RMSE=[]\n",
    "\n",
    "    if modelrun=='09_16':\n",
    "        snow,x1,y1=Readin_SnowModel_0916(forcing,year,'snod')\n",
    "    if modelrun=='36yrs':\n",
    "        snow,x1,y1=Readin_SnowModel_36(forcing,'snod')\n",
    "    data=(np.loadtxt('/Volumes/n4_cpdata/scb/SNOW_DATA/NPOLAR/Read_in_magna/all_data.txt'))\n",
    "    year=data[:,0]\n",
    "    month=data[:,1]\n",
    "    day=data[:,2]\n",
    "    lats=data[:,3]\n",
    "    lons=data[:,4]\n",
    "    nice_snow=data[:,5]\n",
    "    modelled_snow=[]\n",
    "\n",
    "    nice_snow_keep=[]\n",
    "    lats_keep=[]\n",
    "    lons_keep=[]\n",
    "\n",
    "\n",
    "    for point in range (0, len(nice_snow),1):\n",
    "                if modelrun=='09_16':\n",
    "                    snow_model=Get_daily_data_0916(snow,int(year[point]),int(month[point]),int(day[point]))\n",
    "                if modelrun=='36yrs':\n",
    "                    snow_model=Get_daily_data_36(snow,int(year[point]),int(month[point]),int(day[point]))\n",
    "                XX,YY = np.meshgrid(np.arange(snow_model.shape[1]),np.arange(snow_model.shape[0]))\n",
    "                table = np.vstack((XX.ravel(),YY.ravel())).T\n",
    "                x2, y2=np.meshgrid(lons[point], lats[point])\n",
    "                outProj = Proj(init='epsg:3408')\n",
    "                inProj = Proj(init='epsg:4326') #lat lon was using 4326\n",
    "                #N-ICE points are transformed to EASE grid \n",
    "                xx, yy = transform(inProj,outProj,x2,y2)\n",
    "                model_grid = list( zip(np.ravel(x1), np.ravel(y1)) ) \n",
    "                target_pts = [xx[0][0], yy[0][0]] \n",
    "                if (str(target_pts[0])=='nan' or str(target_pts[1])=='nan'):\n",
    "                    continue\n",
    "                distance, index = scipy.spatial.cKDTree(model_grid).query(target_pts)  #cKDTree is faster than KDTree for simple queries like this\n",
    "                distance\n",
    "                # the nearest model location (in lat and lon)\n",
    "                #model_loc_coord = [coord for i, coord in enumerate(model_grid) if i==index]\n",
    "                nearest_x=table[index][0]\n",
    "                nearest_y=table[index][1]\n",
    "                modelled_snow.append(snow_model[nearest_x, nearest_y])\n",
    "                nice_snow_keep.append(nice_snow[point])\n",
    "                lats_keep.append(lats[point])\n",
    "                lons_keep.append(lons[point])\n",
    "\n",
    "\n",
    "    mean_bias.append(np.nanmean(np.array(modelled_snow)-np.array(nice_snow_keep)))\n",
    "    RMSE.append(np.nanmean((np.array(modelled_snow)-np.array(nice_snow_keep))**2.0)**(1/2.0))\n",
    "\n",
    "    #Scatterplot of results\n",
    "    plt.clf()\n",
    "    plt.scatter(nice_snow_keep,modelled_snow)\n",
    "    plt.title('Snowmodel ('+forcing+') vs N-ICE snow depths')\n",
    "    plt.xlabel('N-ICE snow depth (m)')\n",
    "    plt.ylabel('Snow model snow depth (m)')\n",
    "    plt.savefig(savepath+'nice_comparison_'+str(forcing)+str(modelrun)+'scatter.png')\n",
    "    plt.show()\n",
    "    \n",
    "forcings=['erai', 'merra']\n",
    "np.savetxt(filepath+'_stats.txt',np.c_[forcings, mean_bias, RMSE],fmt='%s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
